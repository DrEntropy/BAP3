# Hierarchical Models {#sec-hierarchical}

> "Something, something" - some one

In @sec-programming_probabilistically we saw the tips example where we had multiple groups in our data, one for each of four days, Thursday, Friday, Saturday, and Sunday. We decided to model each group separately. That's sometimes fine, but we should be aware of our assumptions. By modeling each group independently we assumed the groups as unrelated. In other words, we are assuming that knowing the tip for one day does not give us any information about the tip for another day. That could be a too strong assumption. Would it be possible to build a model that allows us to share information between groups? That's not only possible, that's the main topic of this chapter, Lucky you! In this chapter, we will cover the following topics:

* Hierarchical models
* Partial pooling
* Shrinkage


## Sharing information, sharing priors

Hierarchical models are also known as multilevel models, mixed-effects models, random-effects models, or nested models. They are particularly useful when dealing with data that can be described as grouped or having different levels, like data nested within geographic regions (like cities belonging to a province and provinces belonging to a country), or with a hierarchical structure (e.g., students nested within schools, or patients nested within hospitals) or repeated measurements on the same individuals.

Hierarchical models are a natural way to share information between groups. In a hierarchical model, the parameters of the prior distributions are themselves given a prior distribution. These higher-level priors are often called hyper-priors, hyper means over in Greek. Having hyper-priors allows the model to share information between groups, while still allowing differences between groups. In other words, we can think of the parameters of the prior distributions as belonging to a common population of parameters. @fig-hierarchical_model shows a diagram with the high-level differences between a pooled model (a single group), an unpooled model (all separated groups) and a hierarchical model, also known as a partially-pooled model. 


![Diagram showing the differences between a pooled model, an unpooled model, and a hierarchical model.](fig/hierarchical_model.pdf){#fig-hierarchical_model width=80%}

## Hierarchical shifts

Proteins are molecules formed by 20 units, called amino acids, each amino acid can appear in a protein 0 or more times. Just as a melody is defined by a sequence of musical notes, a protein is defined by a sequence of amino acids. Some musical note variations can result in small variations of the melody and other variations in completely different melodies. Something similar happens with proteins. One way to study proteins is by using nuclear magnetic resonance (the same technique used for medical imaging). This technique allows us to measure various quantities, one of which is called a chemical shift. You may remember we already saw an example using chemical shifts in @sec-programming_probabilistically. 

Suppose we want to compare a theoretical method to compute chemical shifts against the experimental observations, among other reasons to evaluate the ability of the theoretical method to reproduce the experimental values. Luckily for us, someone already performed the experiments and the theoretical calculations and we just need to compare them. The following data set contains chemical shift values for a set of proteins. If you inspect the DataFrame `cs_data` you will see that it has 4 columns:

1. The first is a code that identifies the protein (you can get a lot of information about that protein by entering that code at https://www.rcsb.org/.).
2. The second column has the name of the amino acid (you can verify that there are only 19 unique names, one of the amino acids is missing from this dataset).
3. The third contains theoretical values of chemical shifts (calculated using quantum methods).
4. The fourth has experimental values.

Now that we have the data, how we should proceed? One option is to take the empirical differences and fit a Gaussian or maybe Student's T model. Because amino acids are a family of chemical compounds it would make sense to assume they are all the same and estimate a single Gaussian for all the differences. But you may object there are 20 different kinds of amino acids, each one with different chemical properties and hence a better choice is to fit 20 separated Gaussians. What we should do?

Let's take a moment to think about which option is the best. If we combine all the data our estimates are going to be more accurate, but we will not be able to get information from individual groups (amino acids). On the contrary, if we treat them as separate groups we will get a much more detailed analysis but with less accuracy. What we should do?

When in doubt, everything![^all], well kind of. We can build a hierarchical model, in that way we allow estimates at the group level, but with the restriction that they all belong to a larger group or population. To better understand this, let's build a hierarchical model for the chemical shift data.

[^all]: Not sure this is good general advice for your life, but I like the song  <https://www.youtube.com/watch?v=1di09XZUlIw>

To see the difference between a non-hierarchical (un-pooled) model and a hierarchical one, we are going to build two models. The first one is essentially the same as the `comparing_groups` model from @sec-programming_probabilistically.


```python
with pm.Model(coords=coords) as cs_nh:         
    μ = pm.Normal('μ', mu=0, sigma=10, dims="aa") 
    σ = pm.HalfNormal('σ', sigma=10, dims="aa") 
 
    y = pm.Normal('y', mu=μ[idx], sigma=σ[idx], observed=diff) 
     
    idata_cs_nh = pm.sample()
```

Now, we will build the hierarchical version of the model. We are adding two hyper-priors, one for the mean of $\mu$ and one for the standard deviation of $\mu$. We are leaving $\sigma$ without hyper-priors, in other words, we are assuming the variance between observed and theoretical values should be the same for all groups. This is a modeling choice, you may face a problem where this seems unacceptable and you may consider it necessary to add a hyper-prior for $\sigma$; feel free to do that.

```python
with pm.Model(coords=coords) as cs_h:
    # hyper_priors
    μ_mu = pm.Normal('μ_mu', mu=0, sigma=10)
    μ_sd = pm.HalfNormal('μ_sd', 10)

    # priors
    μ = pm.Normal('μ', mu=μ_mu, sigma=μ_sd, dims="aa") 
    σ = pm.HalfNormal('σ', sigma=10, dims="aa")

    # likelihood
    y = pm.Normal('y', mu=μ[idx], sigma=σ[idx], observed=diff) 

    idata_cs_h = pm.sample()
```

@fig-cs_nh_vs_h shows the graphical representation of `cs_h` and `cs_nh` models. We can see that we have one more level for `cs_h` representing the hyper-priors for $\mu$. 

![Graphical representation of the non-hierarchical (left) and hierarchical (right) models for the chemical shift data. Each subfigure was generated with the function pm.model_to_graphviz(.)](fig/cs_nh_vs_h.png){#fig-cs_nh_vs_h width="80%"}

We are going to compare the results using ArviZ's `plot_forest` function. We can pass more than one model to this function. This is useful when we want to compare the values of parameters from different models such as with the present example. On @fig-csh_vs_csnh we have a plot for the 40 estimated means, one per amino acid (20) times the two models. We also have their 94% HDI and the inter-quantile range (the central 50% of the distribution). The vertical dashed line is the global mean according to the hierarchical model. This value is close to zero, as expected for theoretical values faithfully reproducing experimental ones. The most relevant part of this plot is that the estimates from the hierarchical model are pulled toward the partially-pooled mean, or equivalently they are shrunken in comparison to the un-pooled estimates. You will also notice that the effect is more notorious for those groups farther away from the mean (such as `PRO`) and that the uncertainty is on par or smaller than that from the non-hierarchical model. The estimates are partially pooled because we have one estimate for each group, but estimates for individual groups restrict each other through the hyper-prior. Therefore, we get an intermediate situation between having a single group, all chemical shifts together, and having 20 separated groups, one per amino acid. And that is ladies, gentlemen, and non-binary-gender-fluid people, the beauty of hierarchical models.

![Chemical shift differences for the hierarchical and non-hierarchical models.](fig/csh_vs_csnh.png){#fig-csh_vs_csnh}

## Water quality

Suppose we want to analyze the quality of water in a city, so we take samples by dividing the city into neighborhoods. We may think we have two options to analyze this data:

* Study each neighborhood as a separate entity
* Pool all the data together and estimate the water quality of the city as a single big group

Probably you already noticed the pattern here. We can justify the first option by saying we obtain a more detailed view of the problem, which otherwise could become invisible or less evident if we average the data. The second option can be justified by saying that if we pool the data, we obtain a bigger sample size and hence a more accurate estimation. But we already know we have a third option, we can do a hierarchical model!

For this example, we are going to use synthetic data. I love using synthetic data, it is a great way to understand things. If you don't understand something simulate it! There are many uses for synthetic data. Here we are going to imagine we have collected water samples from three different regions of the same city and we have measured the lead content of water; samples with concentrations of lead above recommendations from the World Health Organization (WHO) are marked with zero and samples with values below the recommendations are marked with one. This is a very simple scenario, in a more realistic example, we would have a continuous measurement of lead concentration and probably many more groups. Nevertheless, for our current purposes, this example is good enough to uncover the details of hierarchical models. We can generate the synthetic data with the following code:

```python
N_samples = [30, 30, 30]
G_samples = [18, 18, 18]
group_idx = np.repeat(np.arange(len(N_samples)), N_samples)
data = []
for i in range(0, len(N_samples)):
    data.extend(np.repeat([1, 0], [G_samples[i], N_samples[i]-G_samples[i]]))
```

We are simulating an experiment where we have measured three groups, each one consisting of a certain number of samples; we store the total number of samples per group in the `N_samples` list. Using the `G_samples` list, we keep a record of the number of good-quality samples per group. The rest of the code is there just to generate a list of the data, filled with zeros and ones.

The model for this problem is similar to the one we used for the coin problem, except for two important features:

* We have defined two hyper-priors that will influence the beta prior.
* Instead of putting hyper-priors on the parameters $\alpha$ and $\beta$, we are defining the beta distribution in terms of $\mu$, the mean, and $\nu$, the concentration (or precision) of the beta distribution. The precision is analog to the inverse of the standard deviation; the larger the value of $\nu$, the more concentrated the beta distribution will be. In statistical notation, our model is:

$$
\begin{aligned}
\mu &\sim \text{Beta}(\alpha_{\mu}, \beta_{\mu}) \\
\nu &\sim \mathcal{HN}(\sigma_{\nu}) \\
\theta_i &\sim \text{Beta}(\mu, \nu) \\
y_i &\sim \text{Bernoulli}(\theta_i)
\end{aligned}
$$


Notice we are using the subindex $i$ to indicate that the model has groups with different values for some of the parameters. That is, not all parameters are shared between the groups. Using Kruschke diagrams (see @fig-beta_binomial_hierarchical_dag), we can see that the new model has one additional level compared to the one from @fig-beta_binomial_dag. Notice also that for this model we are parametrizing the Beta prior distribution in terms of $\mu$ and $\nu$ instead of $\alpha$ and $\beta$. This is a common practice in Bayesian statistics, and it is done because $\mu$ and $\nu$ are more intuitive parameters than $\alpha$ and $\beta$. 

![Hierarchical model](/fig/beta_binomial_hierarchical_dag.pdf){#fig-beta_binomial_hierarchical_dag width=40%}

Let's write the model in PyMC:

```python
with pm.Model() as model_h:
    # hypyerpriors
    μ = pm.Beta('μ', 1, 1)
    ν = pm.HalfNormal('ν', 10)
    # prior
    θ = pm.Beta('θ', mu=μ, nu=ν, shape=len(N_samples))
    # likelihood
    y = pm.Bernoulli('y', p=θ[group_idx], observed=data)

    idata_h = pm.sample()
```

### Shrinkage

To show you one of the main consequences of hierarchical models, I will require your assistance, so please join me in a brief experiment. I will need you to print and save the summary computed with `az.summary(idata_h)`. Then, I want you to re-run the model two more
times after making small changes to the synthetic data. Remember to save the summary after each run. In total, we will have three runs:

* One run setting all the elements of G_samples to 18
* One run setting all the elements of G_samples to 3
* One last run setting one element to 18 and the other two to 3

Before continuing, please take a moment to think about the outcome of this experiment. Focus on the estimated mean value of $\theta$ in each experiment. Based on the first two runs of the model, could you predict the outcome for the third case?

If we put the result in a table, we get something more or less like this; remember that small variations could occur due to the stochastic nature of the sampling process:

| G_samples  |        Mean      |
|------------|------------------|
| 18, 18, 18 |  0.6,  0.6,  0.6 |
|  3,  3,  3 | 0.11, 0.11, 0.11 |
| 18,  3,  3 | 0.55, 0.13, 0.13 |

In the first row, we can see that for a dataset of 18 good samples out of 30, we get a mean value for $\theta$ of 0.6; remember that now the mean of $\theta$ is a vector of three elements, one per group. Then, on the second row, we have only 3 good samples out of 30 and the mean of $\theta$ is 0.11. These results should not be surprising, our estimates are practically the same as the empirical means. The interesting part comes in the third row. Instead of getting a mix of the mean estimates of $\theta$ from the other two rows, such as
0.6, 0.11, and 0.11, we get different values, namely 0.55, 0.13, and 0.13.

What on Earth happened? Did we make a mistake somewhere? Nothing like that. What we are seeing is that the estimates shrunk toward the common mean. This is totally OK, indeed this is just a consequence of our model; by using hyper-priors, we are estimating the parameters of the Beta prior distribution from the data. Each group is informing the rest, and each group is informed by the estimation of the others. 

::: callout-note
In a hierarchical model groups sharing a common hyper-prior are effectively sharing information through the hyper-prior. This results in shrinkage, that is individual estimates are shrunk toward the common mean. By partially pooling the data; we are modeling the groups as some middle between the groups being independent from each other and being a single big group.
:::

@fig-idata_h_posterior shows the posterior estimates of $\mu$ and $\nu$ pluged into a Beta distribution. In other words, this is the posterior distribution of the inferred Beta "prior" distribution.

![Posterior distribution of the inferred Beta "prior" distribution](/fig/idata_h_posterior.png){#fig-idata_h_posterior width=80%}


Why is shrinkage desirable? Because it contributes to more stable inferences. This is, in many ways, similar to what we saw with the Student's t-distribution and the outliers, using a heavy-tailed distribution results in a more robust model to data points away from the mean. Introducing hyper-priors results in a more conservative model (probably the first time I've used "conservative" in a flattering way), one that is less responsive to extreme values in individual groups. Imagine that the samples size are different from each neighborhood, some small, some larger; the smaller the sample size, the easier it is to get bogus results. At an extreme, if you take only one sample in a given neighborhood, you may just hit the only really old lead pipe in the whole neighborhood or, on the contrary, the only one made out of PVC. In one case, you will overestimate the bad quality and in the other underestimate it. Under a hierarchical model, the miss-estimation of one group will be ameliorated by the information provided by the other groups. A larger sample size will also do the trick but, more often than not, that is not an option.

The amount of shrinkage depends on the data; a group with more data will pull the estimate of the other groups harder than a group with fewer data points. If several groups are similar and one group is different, the similar groups are going to inform the others of their similarity and reinforce a common estimation, while they are going to pull toward them the estimation for the less similar group; this is exactly what we saw in the previous example. The hyper-priors also have a part in modulating the amount of shrinkage. We can effectively use an informative prior distribution to shrink our estimate to some reasonable value if we have trustworthy information about the group-level distribution.

Nothing prevents us from building a hierarchical model with just two groups—but we would prefer to have several groups. Intuitively, the reason is that getting shrinkage is like assuming each group is a data point, and we are estimating the standard deviation at the group level. Generally, we do not trust an estimation with too few data points unless we have a strong prior to inform our estimation. Something similar is true for a hierarchical model. 



## Hierarchies all the way up

Various data structures lend themselves to hierarchical descriptions that can encompass multiple levels. For example, consider professional football (soccer) players. As in many other sports, players have different fielding positions. We may be interested in estimating some skill metrics for each player, for the positions, and for the overall group of professional football players. This kind of hierarchical structure can be found in many other domains as well, such as:

* Medical research: Suppose we are interested in estimating the effectiveness of different drugs for treating a particular disease. We can categorize patients based on their demographic information, disease severity, and other relevant factors and build a hierarchical model to estimate the probability of cure or treatment success for each subgroup. We can then use the parameters of the subgroup distribution to estimate the overall probability of cure or treatment success for the entire patient population.

* Environmental science: Suppose we are interested in estimating the impact of a certain pollutant on a particular ecosystem. We can categorize different habitats within the ecosystem (e.g., rivers, lakes, forests, wetlands) and build a hierarchical model to estimate the distribution of pollutant levels within each habitat. We can then use the parameters of the habitat distribution to estimate the overall distribution of pollutant levels within the ecosystem.

* Market research: Suppose we are interested in understanding the purchasing behavior of consumers for a particular product across different regions. We can categorize consumers based on their demographic information (e.g., age, gender, income, education) and build a hierarchical model to estimate the distribution of purchasing behavior for each subgroup. We can then use the parameters of the subgroup distribution to estimate the distribution of purchasing behavior for the overall group of consumers.

Going back to our football players, We have collected data from the *Premier League*, *Ligue 1*, *Bundesliga*, *Serie A* and *La Liga*, over the course of four years (2017 to 2020). Let's suppose we are interested in the goals-per-shot metric. This is what statisticians usually call a *success rate*, and we can estimate it with a Binomial model where the parameter $n$ is the number of shots and the observations $y$ is the number of goals. This leaves us with an unknown value for $p$, in previous examples we have been calling this parameter $\theta$ and we have used a Beta distribution to model it. We will do the same now, but hierarchically. See @fig-beta_binomial_hierarchical_subjects_dag for a graphical representation of the entire model. $\theta$ represents the "success rate" for each player, and thus it is a vector of size `n_players`. We use a Beta distribution to model $\theta$. The hyperparameters of the Beta distribution will be the vectors $\mu_p$ and $\nu_p$, which are vectors of size 4, representing the four positions in our dataset(defender `DF`, midfielder `MF`, forward `FW` and goalkeeper `GK`). We will need to properly index the vectors $\mu_p$ and $\nu_p$ to match the total number of players. Finally, we will have two global parameters, $\mu$ and $\nu$, representing the professional football players


![Hierarchical model for the football players example. Notice how we have one more level than in previous hierarchical models](/fig/beta_binomial_hierarchical_subjects_dag.png){#fig-beta_binomial_hierarchical_subjects_dag width=40%}


The PyMC model is defined in the following block of code. The `pm.Beta('mu', 1.7, 5.8)` was chosen with the help of PreliZ as a prior with 90% of the mass between 0 and 0.5. This is an example of a weakly informative prior, as it is little doubt that a success rate of 0.5 is a high value. Sports statistics are well-studied and there is a lot of prior information that could be used to define stronger priors. For this example, we will settle on this prior. A similar justification can be done for the prior `pm.Gamma('nu', mu=125, sigma=50)`, which we define as the maximum entropy Gamma prior with 90% of the mass between 50 and 200. 


```python
coords = {"pos": pos_codes}
with pm.Model(coords=coords) as model_football:
    # Hyper parameters
    μ = pm.Beta('μ', 1.7, 5.8) 
    ν = pm.Gamma('ν', mu=125, sigma=50)

    
    # Parameters for positions
    μ_p = pm.Beta('μ_p',
                       mu=μ,
                       nu=ν,
                       dims = "pos")
    
    ν_p = pm.Gamma('ν_p', mu=125, sigma=50, dims="pos")
 
    # Parameter for players
    θ = pm.Beta('θ', 
                    mu=μ_p[pos_idx],
                    nu=ν_p[pos_idx])
    
    _ = pm.Binomial('gs', n=football.shots.values, p=θ, observed=football.goals.values)

    idata_football = pm.sample()
```

On the top panel of @fig-beta_binomial_hierarchical_subjects_global_mus we have the posterior distribution for the global parameter $\mu$. The posterior distribution is close to 0.1. Meaning that overall for a professional football player (from a top league), the probability of scoring a goal is on average 10%. This is a reasonable value, as scoring goals is not an easy task and we are not discriminating positions, i.e. we are considering players whose main role is not scoring goals. On the middle panel, we have the estimated $mu_p$ value for the forward position, as expected it is higher than the global parameter $\mu$. On the bottom panel, we have the estimated $\theta$ value for Lionel Messi, with a value of 0.17, which is higher than the global parameter $\mu$ and the forward position $\mu_p$ value. This is also expected, as Lionel Messi is the best football player in the world, and his main role is scoring goals.

![Posterior distribution for the mean global parameter (top), mean forward position (middle) and $\theta$ parameter for Messi (bottom).](/fig/beta_binomial_hierarchical_subjects_global_mus.png){#fig-beta_binomial_hierarchical_subjects_global_mus width=80%}


@fig-beta_binomial_hierarchical_subjects_positions shows a forest plot for the posterior distribution for the parameter $\mu_p$. The posterior distribution for the forward position is centered around 0.13, as we already saw, and is the highest of the four. This makes sense as the role of the players at a forward position is scoring goals as well as assisting them. The lowest value of $\mu_p$ is for the goalkeeper position. This is expected, as the main role is to stop the opposing team from scoring, and not to score goals. The interesting aspect is that the uncertainty is very high, this is because we have very few goalkeepers scoring goals in our dataset, 3 to be precise. The posterior distributions for the defender and midfielder positions are somewhat in the middle, being slightly higher for the midfielder. We can explain this as the main role of a midfielder is to defend and attack, and thus the probability of scoring a goal is higher than a defender but lower than a forward. 


![Posterior distribution for the parameter $\mu_p$, the mean position](/fig/beta_binomial_hierarchical_subjects_positions.png){#fig-beta_binomial_hierarchical_subjects_positions}


::: callout-note
It is possible to create hierarchical models with as many levels as we want. But unless the problem necessitates additional structure, adding more levels than required does not enhance the quality of our model or inferences. Instead, we will get entangled in a web of hyper-priors and hyperparameters without the ability to assign any meaningful interpretation to them. The goal of building models is to make sense of data, and thus useful models are usually those that reflect and take advantage of the structure of the data.
:::



## Summary

In this chapter, we have presented one of the most important concepts to learn from this book: hierarchical models. We can build hierarchical models every time we can identify subgroups in our data. In such cases, instead of treating the subgroups as separated entities or ignoring the subgroups and treating them as a single group, we can build a model to partially pool information among groups. The main effect of this partial pooling is that the estimates of each subgroup will be biased by the estimates of the rest of the subgroups. This effect is known as shrinkage, and in general, is a very useful trick that helps to improve inferences by making them more conservative (as each subgroup informs the others by pulling estimates toward it) and more informative. We get estimates at the subgroup level and the group level.

Paraphrasing the Zen of Python, we can certainly say *hierarchical models are one honking great idea, let's do more of those!* In the following chapters, we will keep building hierarchical models and learn how to use them to build better models. We will also discuss how hierarchical models are related to the pervasive overfitting/underfitting issue in statistics and machine learning in @sec-model_comparison. In @sec-inference_engines, we will discuss some technical problems that we may find when sampling from hierarchical models and how to diagnose and fix those problems.


## Exercises

1. Using your own words explain the following concepts in two or three sentences:

* Complete pooling
* No pooling
* Partial pooling

2. Repeat the exercise we did with `model_h`. This time, without a hierarchical structure, use a flat prior such as $\text{Beta}(\alpha=1, \beta=1)$. Compare the results of both models.

3. Create a hierarchical version of the tips example from @sec-programming_probabilistically by partially pooling across the days of the week. Compare the results to those obtained without the hierarchical structure.

4. For each subpanel in @fig-beta_binomial_hierarchical_subjects_global_mus add a reference line representing the empirical mean value, at each level, i.e. the global mean, the forward mean, and Messi's mean. Compare the empirical values to the posterior mean values. What do you observe?

5. Amino acids are usually grouped into the categories like `polar`, `non-polar`, `charged`, and `special`. Build a hierarchical model similar to `cs_h` but including a group effect for the amino acid category. Compare the results to those obtained in this chapter.


